{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/pip install opencv-python\n",
    "#pip install mediapipe\n",
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 13:51:21.291 Python[3319:73441] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        out.write(frame)\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pose estimation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721982094.044814   73441 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1721982094.150377   73840 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1721982094.157475   73847 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/Applications/ms/.venv/lib/python3.12/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        if results.pose_landmarks:\n",
    "             cv2.imshow('frame',frame)\n",
    "            # do something with the landmarks\n",
    "             \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Personal Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises = {\n",
    "    'Squats': {\n",
    "        'nose': (0.4, 0.6),\n",
    "        'left_shoulder': (0.2, 0.4),\n",
    "        'right_shoulder': (0.6, 0.8),\n",
    "        'left_hip': (0.2, 0.4),\n",
    "        'right_hip': (0.6, 0.8),\n",
    "        'left_knee': (0.4, 0.6),\n",
    "        'right_knee': (0.4, 0.6),\n",
    "        'left_ankle': (0.2, 0.4),\n",
    "        'right_ankle': (0.6, 0.8)\n",
    "    },\n",
    "    'Pushups': {\n",
    "        'nose': (0.4, 0.6),\n",
    "        'left_shoulder': (0.2, 0.4),\n",
    "        'right_shoulder': (0.6, 0.8),\n",
    "        'left_elbow': (0.2, 0.4),\n",
    "        'right_elbow': (0.6, 0.8),\n",
    "        'left_wrist': (0.2, 0.4),\n",
    "        'right_wrist': (0.6, 0.8)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we define the correct pose for two exercises, Squats and Pushups. For each exercise, we define the acceptable range of values for each landmark returned by the pose estimation model.\n",
    "\n",
    "Next, we need to define a function to check if the person is performing the exercise correctly. We will check if the landmarks returned by the pose estimation model fall within the acceptable range of values defined for the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exercise(landmarks, exercise):\n",
    "    for landmark, range in exercise.items():\n",
    "        x = landmarks[landmark].x\n",
    "        y = landmarks[landmark].y\n",
    "        if x < range[0] or x > range[1] or y < range[0] or y > range[1]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we define a function to check if the landmarks fall within the acceptable range of values for the exercise. The function returns True if the landmarks fall within the acceptable range of values, otherwise it returns False.\n",
    "\n",
    "Now that we can check if the person is performing the exercise correctly, we can provide feedback in real-time. We can draw lines and circles on the video to indicate the correct posture for the exercise. We can also display text on the video to provide feedback on the personâ€™s performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'nose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, landmark \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark):\n\u001b[1;32m     19\u001b[0m     landmarks[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandmark_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m landmark\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcheck_exercise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlandmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexercises\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSquats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     21\u001b[0m     draw_pose(frame, landmarks, exercises[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSquats\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m check_exercise(landmarks, exercises[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPushups\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36mcheck_exercise\u001b[0;34m(landmarks, exercise)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_exercise\u001b[39m(landmarks, exercise):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark, \u001b[38;5;28mrange\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exercise\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlandmarks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlandmark\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m      4\u001b[0m         y \u001b[38;5;241m=\u001b[39m landmarks[landmark]\u001b[38;5;241m.\u001b[39my\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mrange\u001b[39m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m x \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mrange\u001b[39m[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m y \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mrange\u001b[39m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m y \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mrange\u001b[39m[\u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'nose'"
     ]
    }
   ],
   "source": [
    "def draw_pose(frame, landmarks, exercise):\n",
    "    for landmark, _ in exercise.items():\n",
    "        x = int(landmarks[landmark].x * frame.shape[1])\n",
    "        y = int(landmarks[landmark].y * frame.shape[0])\n",
    "        cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "    cv2.putText(frame, \"Correct posture\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = {}\n",
    "            for i, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "                landmarks[f'landmark_{i}'] = landmark\n",
    "            if check_exercise(landmarks, exercises['Squats']):\n",
    "                draw_pose(frame, landmarks, exercises['Squats'])\n",
    "            elif check_exercise(landmarks, exercises['Pushups']):\n",
    "                draw_pose(frame, landmarks, exercises['Pushups'])\n",
    "            else:\n",
    "                cv2.putText(frame, \"Incorrect posture\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we capture frames from the webcam and pass them to the pose estimation model.\n",
    "\n",
    "We then check if the person is performing Squats or Pushups correctly using the check_exercise() function. If the person is performing the exercise correctly, we draw the correct pose on the video using the draw_pose() function.\n",
    "\n",
    "If the person is not performing the exercise correctly, we display a message on the video indicating incorrect posture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
